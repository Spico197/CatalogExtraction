# 文本片段合并代码使用说明

## 模型训练

1. 检查 `examples/text_concat/train` 中的 `config.yaml` 配置文件，分别配置如下项目：

```yaml
# 必填：会根据任务名称创建任务文件夹
name: text_concat
# 必填：数据文件夹位置，建议使用绝对路径
data_dir: /data4/tzhu/DocTree/data/text_concat
# 必填：预训练模型所在位置，可填写模型文件夹位置使用本地预加载模式，或填写缩写使用在线下载模式
plm_dir: hfl/rbt3
# 必填：希望在哪个文件夹下创建任务文件夹
output_dir: /data4/tzhu/DocTree/outputs
# 必填：设置训练模式
mode: train
# 必填：设置设备号
device: cuda:0
# 必填：取消debug模式（debug模式会默认只加载少量数据）
debug_mode: false
```

2. 上述配置检查完毕之后，修改shell文件( `examples/text_concat/train/run.sh` )中的配置文件路径。

3. 开始训练

```bash
$ bash examples/text_concat/train/run.sh
```

## 模型推理

模型的推理和使用可参考 `examples/text_concat/inference/run.py` 中的使用方式。只需在代码中按如下方式调用即可：

```python
# 导入任务类
from doctree.tasks.text_concat_task import TextConcatTask

# 自动导入配置文件和模型
inference_tool = TextConcatTask.from_taskdir(
    "所在任务的文件夹，对应训练配置文件中的 output_dir/name",
    load_best_model=True,       # 导入模型
    load_best_optimizer=False,  # 不导入优化器参数
    load_train_data=False,      # 不导入训练数据
    load_dev_data=False,        # 不导入开发数据
    load_test_data=False,       # 不导入测试数据
    initialize=True,            # 设置随机种子和log文件位置
    makedirs=False,             # 不创建新的任务文件夹
    dump_configfile=False,      # 不保存配置文件
)
text_pair_data = [
    {"sentence1": "2020年", "sentence2": "秋季运动会"},
    {"sentence1": "今天的旅程就到这里了", "sentence2": "欢迎来到苏州"},
    {"sentence1": "版本", "sentence2": "2.0"},
]

# 所有的预测结果中，`1` 表示两句拼接，`2` 表示两句不拼接
# 我们提供两个预测接口，一个是以 batch 为单位进行预测，输入为 List[dict]
# 下面这个例子的期望输出为：
# [{'sentence1': '2020年', 'sentence2': '秋季运动会', 'pred_tag': 1}, {'sentence1': '今天的旅程就到这里了', 'sentence2': '欢迎来到苏州', 'pred_tag': 1}, {'sentence1': '版本', 'sentence2': '2.0', 'pred_tag': 1}]
concat_result = inference_tool.predict_batch(text_pair_data)
# 另外一个接口是单个预测的接口，直接返回数字结果
concat_result = inference_tool.predict("第一句", "第二句")
```
